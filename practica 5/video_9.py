# -*- coding: utf-8 -*-
"""video 9

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uOgqEQvZBenGUG5tgOV4IzBiJWbfc2zZ
"""

import pandas as pd

datos = pd.read_csv("Customer.csv")

datos.shape

datos.head()

diccionario = {"Si" : 1,"No" : 0}
datosmodificados = datos[["Conyuge","Dependientes","TelefonoFijo","PagoOnline","Churn"]].replace(diccionario)
datosmodificados.head()

#Transformación con get_dummies
dummie_datos = pd.get_dummies (datos.drop(['Conyuge', 'Dependientes', 'TelefonoFijo', 'PagoOnline','Churn'],
axis=1))
#Unión de los datos transformados con los que ya teníamos
datos_final = pd.concat( [datosmodificados, dummie_datos], axis=1)

datos_final.head()

datos_final.shape

#TIP
pd.set_option('display.max_columns', 39)

datos_final.head()

Xmaria = [[0,0,1,1,0,0,39.90,1,0,0,0,1,0,1,0,0,0,0,1,1,1,0,0,1,0,1,0,0,0,0,1,0,0,1,0,0,0,1]]

type (Xmaria)

# Commented out IPython magic to ensure Python compatibility.
#variable target está desbalanceada
import seaborn as sns
# %matplotlib inline
ax = sns.countplot (x='Churn', data=datos_final)

datos_final.Churn.value_counts()

#biblioteca para balancear los datos utilizando over_sampling
from imblearn.over_sampling import SMOTE

#dividiendo los datos en características y target
X = datos_final.drop('Churn', axis = 1)
Y = datos_final [ 'Churn']

smt = SMOTE (random_state=123)
X, Y = smt.fit_resample (X, Y)

#unión de los datos balanceados
datos_final = pd.concat((X, Y), axis=1)

#verificación 1 - unión de los datos
datos_final.head (2)

#verificación 2 - balanceamiento
ax = sns.countplot (x='Churn', data=datos_final)

datos_final. Churn.value_counts ( )

#2.2 - KNN en la práctica

Xmaria

#ymaria = ?

#División #en inputs y outputs I
X = datos_final.drop('Churn', axis = 1)
y = datos_final['Churn']

#biblioteca para padronizar los datos
from sklearn.preprocessing import StandardScaler

norm = StandardScaler()
X_normalizado = norm.fit_transform(X)
X_normalizado

X_normalizado [0]

Xmaria_normalizado = norm.transform(pd.DataFrame(Xmaria, columns = X.columns))
Xmaria_normalizado

import numpy as np

a = Xmaria_normalizado

b = X_normalizado [0]

#1 - comenzamos restando
a - b

#2 después realizamos
np.square (a-b)

#3 realizamos la suma
np.sum(np.square (a-b))

#4 - finalmente obtenemos la
np.sqrt(97.82832324280224)

#2.3 Implementando el modelo
#biblioteca para división de los datos
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_normalizado, y, test_size=0.3, random_state=123)

"""Entrenamiento y prueba"""

#biblioteca para crear el modelo de machine learning
from sklearn.neighbors import KNeighborsClassifier

#iniciar el modelo (creamos el modelo) - por default son 5 vecinos
knn = KNeighborsClassifier (metric='euclidean')

#entrenando el modelo con los datos de entrenamiento
knn.fit(X_train, y_train)

#probando el modelo con los datos de prueba
prediccion_knn = knn.predict (X_test)

prediccion_knn